{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bb3f90-f48f-414c-ac65-38f761028532",
   "metadata": {
    "name": "Introduction",
    "collapsed": false
   },
   "source": "Snowpark allows you to write Python, Scala, or Java code to interact with Snowflake data and perform data processing inside the Snowflake database. This enables you to run computations and data transformations closer to the data, reducing the need for moving data between different systems.\n\nIn this introduction, we'll cover:\n1. **What is VaR?**\n2. **Why Snowpark for VaR?**\n3. **Key steps for implementing VaR using Snowpark**\n\n\n---\n\n### 1. What is Value at Risk (VaR)?\n**Value at Risk (VaR)** is a statistical measure used to estimate the **maximum potential loss** of a portfolio over a defined period for a given confidence interval. It's a widely used risk metric in finance. For example, a 95% 1-day VaR of $1 million means that there’s a 95% chance that the portfolio will not lose more than $1 million in a day.\n\n- **VaR Formula (Normal Distribution)**:\n  \\[\n  VaR = Z \\times \\sigma \\times \\sqrt{T}\n  \\]\n  Where:\n  - \\( Z \\) is the Z-score corresponding to the confidence level (e.g., -1.645 for 95% confidence)\n  - \\( \\sigma \\) is the standard deviation (volatility) of returns\n  - \\( T \\) is the time horizon (e.g., 1 day, 10 days)\n\nThere are various methods to calculate VaR:\n- **Historical VaR**: Uses historical data to estimate potential losses.\n- **Parametric VaR**: Assumes the returns follow a normal distribution.\n- **Monte Carlo VaR**: Simulates possible outcomes based on random sampling from the distribution of returns.\n\n### 2. Why Snowpark for VaR?\nSnowpark is useful for VaR because it allows you to:\n- Run your risk models directly on **Snowflake** where your data resides, avoiding data movement.\n- Use **Python** to perform complex operations, such as Monte Carlo simulations and VaR calculations.\n- **Scale computations** seamlessly because Snowpark leverages Snowflake’s distributed architecture.\n\nWith Snowpark, you can run data transformations, simulations, and statistical calculations using familiar Python libraries (e.g., `pandas`, `numpy`, `scipy`) without having to move data out of Snowflake.\n\n### 3. Key Steps for Implementing VaR using Snowpark\n\nHere’s an overview of the steps to calculate VaR in Snowpark:\n\n1. **Connect to Snowflake using Snowpark**:\n   - You create a Snowpark **Session** that connects to your Snowflake account.\n\n2. **Fetch Historical Stock Data**:\n   - Pull historical stock data into Snowflake using **Snowflake tables** or external sources like **Yahoo Finance** using `yfinance`.\n\n3. **Calculate Daily Returns**:\n   - Compute the daily returns based on historical stock prices.\n\n4. **Run Monte Carlo Simulation** (if using Monte Carlo VaR):\n   - Simulate stock returns by generating random numbers based on the historical mean and volatility of the stock.\n\n5. **Calculate VaR**:\n   - Use Snowflake functions (e.g., **approx_percentile()**) to calculate the VaR from the simulated or historical returns.\n\n\n### Advantages of Using Snowpark for VaR:\n- **No data movement**: You don’t need to move data from Snowflake to another environment; everything runs inside Snowflake’s platform.\n- **Scalable**: Snowflake’s architecture scales with your computations, allowing you to run large simulations or calculate VaR for large portfolios.\n- **Python in SQL environment**: Snowpark allows you to leverage Python inside Snowflake, combining the flexibility of Python with Snowflake’s power.\n\n### Conclusion:\nSnowpark offers a seamless way to calculate VaR directly within Snowflake, leveraging Python and Snowflake’s scalable infrastructure. Whether you’re working with historical data or running Monte Carlo simulations, Snowpark can help you efficiently compute risk metrics like VaR without leaving the Snowflake environment.\n"
  },
  {
   "cell_type": "code",
   "id": "e23f9e0d-ba56-47ee-9c3e-c50fe12d51cd",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "!pip install yfinance\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import col, call_builtin\n\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f1e26bc1-4711-409f-a0fd-d884ef9ea79d",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "import numpy as np\nimport yfinance as yf\n#from snowflake.snowpark import Session\n#from snowflake.snowpark.functions import col, call_builtin\n#import snowflake.snowpark.types as T\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75dc67cf-d049-4bba-a800-a7b0b8ea6df7",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "def get_stock_data(symbol, start, end):\n    stock_data = yf.download(symbol, start=start, end=end)\n    stock_data['Daily Return'] = stock_data['Adj Close'].pct_change()\n    stock_data = stock_data.dropna()  # Drop missing values\n    return stock_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b6a043b-7469-4df5-be90-108ed47222c1",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Fetch AAPL stock data\nsymbol = 'AAPL'\nstart_date = '2022-01-01'\nend_date = '2023-12-31'\nstock_data = get_stock_data(symbol, start=start_date, end=end_date)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0327aed1-6fc3-4cec-abde-1bd678d76aba",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "collapsed": false
   },
   "outputs": [],
   "source": "snowpark_df = session.create_dataframe(stock_data)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f78e8f99-23ef-4997-ab4c-607b676894cd",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false
   },
   "outputs": [],
   "source": "snowpark_df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dac74baa-af41-49db-8cc5-36a2c18d8ca6",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 5: Save the Snowpark DataFrame as a new table in Snowflake\ntable_name = \"stock_data_table\"  # Define your table name\n\n# Save the Snowpark DataFrame as a table in the Snowflake database\nsnowpark_df.write.save_as_table(table_name, mode=\"overwrite\")  # Use \"append\" if you want to add to an existing table\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76fd7441-262d-4970-ac56-93a87a275b4f",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 4: Calculate mean and volatility of daily returns\nmean_return = stock_data['Daily Return'].mean()\nvolatility = stock_data['Daily Return'].std()\n\nprint(f\"Mean Return: {mean_return}\")\nprint(f\"Volatility: {volatility}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ae70efb-4a4f-4832-9aa4-f61e13e5d911",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 5: Monte Carlo Simulation of stock returns\nnum_simulations = 10000\ntime_horizon = 1  # 1 day\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea618621-9a51-4757-b1ce-bc0f21d99711",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false
   },
   "outputs": [],
   "source": "def simulate_stock_returns(num_simulations, mean_return, volatility):\n    # Simulate stock returns based on historical mean and volatility\n    simulated_returns = np.random.normal(loc=mean_return, scale=volatility, size=num_simulations)\n    return pd.DataFrame(simulated_returns, columns=[\"return_value\"])\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e3c50b0-49c9-410b-bf64-a8ead5467f6e",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Generate simulated stock returns\nsimulated_returns_df = simulate_stock_returns(num_simulations, mean_return, volatility)\n\n# Step 6: Load simulated returns to Snowflake as a temporary Snowpark DataFrame\nsimulated_returns_snowpark_df = session.create_dataframe(simulated_returns_df)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c93af58a-384c-4c10-a4c5-09f7c2eb6a4b",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false
   },
   "outputs": [],
   "source": "simulated_returns_snowpark_df.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6184fe91-8b70-4424-9790-41827f2b2b7f",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 7: Calculate Value at Risk (VaR) - at 95% confidence level using Snowpark's approx_percentile\nconfidence_level = 0.05\nvar_result = simulated_returns_snowpark_df.select(call_builtin('approx_percentile', col('\"return_value\"'), confidence_level).alias('VaR')).collect()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de88bb8b-22f4-47ca-be16-ed1c610539a5",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false
   },
   "outputs": [],
   "source": "print(var_result)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16b7d7d4-8b89-4564-aeb3-cf48ed815b61",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "outputs": [],
   "source": "var = var_result[0]['VAR']\n\nprint(f\"Value at Risk (VaR) at 95% confidence level: {var}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14ec7a7c-b5a7-4c34-afa3-8c4bf2df4210",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Step 8: Close Snowpark session\nsession.close()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd8389b8-764d-4fcb-a312-cd7985ec7bd2",
   "metadata": {
    "name": "Summary",
    "collapsed": false
   },
   "source": "The VaR score interpretation:\n\nFor example, if your VaR scroe is -0.02978\n\nThe Value at Risk (VaR) score of -0.02978 means there's a 2.98% potential loss on your portfolio (or stock, e.g., AAPL) over the next day, with a 95% confidence level. \n\nHere's a breakdown of what this means and how to interpret whether it's a \"good\" VaR score:\n\n\n### What This VaR Means:\n- **Interpretation**: There’s a **95% probability** that the portfolio’s daily loss will **not exceed 2.98%** of its value. Conversely, there's a **5% chance** that the loss **will exceed 2.98%** in one trading day.\n  \n  For example, if you hold $100,000 worth of AAPL stock, you can expect with 95% confidence that the maximum potential loss in a single day is **$2,928** or less.\n\n### Is This a \"Good\" VaR Score?\nWhether this is a good VaR depends on several factors:\n\n1. **Risk Tolerance**:\n   - If you're a conservative investor with a low risk tolerance, a **2.98% daily loss** might seem high, indicating that AAPL carries a reasonable degree of daily risk.\n   - For aggressive investors, especially those in high-volatility markets (e.g., tech stocks), this level of risk might be acceptable.\n\n2. **Market Conditions**:\n   - **Historical context** is key. During periods of high market volatility (e.g., market crashes, economic downturns), higher VaR scores are expected. Conversely, in stable markets, you'd expect lower VaR scores.\n   - Compare your VaR with the **current market volatility** (e.g., using the VIX index). If the overall market is volatile, your VaR is likely higher than usual.\n\n3. **Comparing with Other Assets**:\n   - It’s important to benchmark the VaR against other assets in your portfolio or similar stocks. AAPL tends to be a more stable, large-cap stock. If you're holding stocks in riskier sectors (e.g., biotech, cryptocurrencies), their VaR could be much higher.\n   \n   Compare this VaR to other stocks you own or to an index like the S&P 500. If AAPL has a **lower VaR** than your other holdings, it might be a \"safer\" part of your portfolio.\n\n4. **Investment Horizon**:\n   - The VaR you calculated is for a **1-day time horizon**. If your investment horizon is longer (e.g., 1 month, 1 year), consider calculating VaR over those periods. A 1-day VaR is primarily useful for traders or those managing daily risk exposure.\n\n5. **Portfolio Size and Diversification**:\n   - If AAPL is a part of a **diversified portfolio**, the portfolio VaR may be lower than the VaR for individual assets. Diversification generally reduces risk because losses in one stock may be offset by gains in another.\n\n### Conclusion:\n- **2.98% daily VaR** is not unusually high for an individual stock, especially for a technology stock like AAPL.\n- Whether it's \"good\" or not depends on your **risk appetite** and your **investment goals**.\n  - For a conservative portfolio, you might aim for a lower VaR, indicating less risk of daily loss.\n  - For a more aggressive portfolio, this VaR might seem relatively modest.\n  \nIf you’re concerned about the risk, you can consider strategies like hedging with options, reducing exposure to the stock, or further diversifying your portfolio.\n\nWould you like to explore strategies for managing risk, or dive deeper into another analysis?"
  }
 ]
}